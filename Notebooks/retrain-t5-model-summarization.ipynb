{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-13T07:46:19.841656Z","iopub.execute_input":"2022-01-13T07:46:19.842224Z","iopub.status.idle":"2022-01-13T07:46:28.453244Z","shell.execute_reply.started":"2022-01-13T07:46:19.842136Z","shell.execute_reply":"2022-01-13T07:46:28.452427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# path_input = '../input/arabic-text-summarization-30-000/wikiHow.csv'\npath_input = '../input/headlines/summary.csv'\n# df['summary'] = df['summary'].replace(r'\\n', '', regex = True)\n\n# df = pd.read_csv(path_input)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-13T07:46:28.455733Z","iopub.execute_input":"2022-01-13T07:46:28.455989Z","iopub.status.idle":"2022-01-13T07:46:31.925557Z","shell.execute_reply.started":"2022-01-13T07:46:28.455959Z","shell.execute_reply":"2022-01-13T07:46:31.923372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import T5Tokenizer\n\ntokenizer = T5Tokenizer(\"../input/arabict5tokenizer/arabic_sentencepiece.model\",\n                               do_lower_case=True, do_basic_tokenize=True, \n                               padding=True, bos_token=\"<s>\", \n                               eos_token=\"</s>\",unk_token=\"<unk>\", \n                               pad_token=\"<pad>\")","metadata":{"execution":{"iopub.status.busy":"2022-01-13T07:46:31.930306Z","iopub.execute_input":"2022-01-13T07:46:31.93054Z","iopub.status.idle":"2022-01-13T07:46:38.758835Z","shell.execute_reply.started":"2022-01-13T07:46:31.930494Z","shell.execute_reply":"2022-01-13T07:46:38.758065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import seaborn as sns\n# from pylab import rcParams\n# import matplotlib.pyplot as plt\n# from matplotlib import rc\n\n# %matplotlib inline\n# %config InlineBackend.figure_format='retina'\n# sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n# rcParams['figure.figsize'] = 16, 10\n\n# text_token_counts = df['text'].apply(lambda x : len(tokenizer.encode(x)))\n# summary_token_counts = df['summary'].apply(lambda x : len(tokenizer.encode(x)))\n# fig, (ax1, ax2) = plt.subplots(1, 2)\n# sns.histplot(text_token_counts, ax=ax1)\n# ax1.set_title('full text token counts')\n# sns.histplot(summary_token_counts, ax=ax2)\n# ax2.set_title('summary text token counts')","metadata":{"execution":{"iopub.status.busy":"2022-01-13T07:46:38.760116Z","iopub.execute_input":"2022-01-13T07:46:38.760337Z","iopub.status.idle":"2022-01-13T07:46:38.763465Z","shell.execute_reply.started":"2022-01-13T07:46:38.760306Z","shell.execute_reply":"2022-01-13T07:46:38.762842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nTEXT_MAX_LEN = 1000\nSUMMARY_MAX_LEN = 100 \nclass SummaryDataset(Dataset):\n    def __init__(\n        self,\n        data: pd.DataFrame = df,\n        tokenizer: T5Tokenizer = tokenizer,\n        text_max_token_len: int = TEXT_MAX_LEN,\n        summary_max_token_len: int = SUMMARY_MAX_LEN\n    ):\n        self.tokenizer = tokenizer\n        self.data = data\n        self.text_max_token_len = text_max_token_len\n        self.summary_max_token_len = summary_max_token_len\n    \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index: int):\n        data_row = self.data.iloc[index]\n\n        text = data_row['text']\n\n        text_encoding = tokenizer(\n            text,\n            max_length=self.text_max_token_len,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            add_special_tokens=True,\n            return_tensors='pt'\n        )\n\n        summary_encoding = tokenizer(\n            data_row['summary'],\n            max_length=self.summary_max_token_len,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            add_special_tokens=True,\n            return_tensors='pt'\n        )\n\n        labels = summary_encoding['input_ids']\n        labels[labels == tokenizer.pad_token_id] = -100\n\n        return dict(\n            input_ids=text_encoding['input_ids'].flatten(),\n            attention_mask=text_encoding['attention_mask'].flatten(),\n            labels=labels.flatten(),\n            decoder_attention_mask=summary_encoding['attention_mask'].flatten()\n        )\n\ndataset = SummaryDataset(df, tokenizer)\ndataloader = DataLoader(dataset, shuffle=True, batch_size=4)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T07:46:38.764682Z","iopub.execute_input":"2022-01-13T07:46:38.765004Z","iopub.status.idle":"2022-01-13T07:46:38.784675Z","shell.execute_reply.started":"2022-01-13T07:46:38.764974Z","shell.execute_reply":"2022-01-13T07:46:38.783951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import T5Config, T5ForConditionalGeneration, AdamW, get_scheduler\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ncheckpoint = torch.load('../input/retrain-t5-model-summarization/t5_Arabic_WikiHow.pth', map_location=device)\n\n# config = T5Config(\n#     vocab_size = tokenizer.vocab_size,\n#     pad_token_id = tokenizer.pad_token_id,\n#     eos_token_id = tokenizer.eos_token_id,\n#     decoder_start_token_id = tokenizer.pad_token_id,\n#     d_model = 300\n# )\n# model = T5ForConditionalGeneration(config)\n\nmodel = checkpoint['model']\nmodel = model.to(device)\n\noptimizer = AdamW(model.parameters(), lr = 0.0001)\n# optimizer = checkpoint['optimizer']\n\nnum_epochs = 5\n# lr_scheduler = get_scheduler(\n#     \"linear\",\n#     optimizer=optimizer,\n#     num_warmup_steps=0,\n#     num_training_steps= 30 * len(dataloader)\n# )\n# lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n\nlast_epoch = checkpoint['epoch']\nprint(f\"{checkpoint['loss']}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-13T07:46:38.786014Z","iopub.execute_input":"2022-01-13T07:46:38.786258Z","iopub.status.idle":"2022-01-13T07:46:46.221535Z","shell.execute_reply.started":"2022-01-13T07:46:38.786226Z","shell.execute_reply":"2022-01-13T07:46:46.220781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\nnum_training_steps = num_epochs * len(dataloader)\nprogress_bar = tqdm(range(num_training_steps))\n\nmodel.train()\nfor epoch in range(num_epochs):\n    for batch in dataloader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        \n        outputs = model(**batch)\n        logits = outputs.logits\n        \n        loss = outputs.loss\n        loss.backward()\n        \n        optimizer.step()\n#         lr_scheduler.step()\n        \n        optimizer.zero_grad()\n        progress_bar.update()\n    \n    torch.save({\n            'epoch':  epoch + last_epoch + 1,\n            'model': model,\n#             'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n            'loss': loss,\n            }, f'./t5_Arabic_WikiHow.pth')\n\n    print(f'epoch: {epoch + last_epoch + 1} -- loss: {loss}')","metadata":{"execution":{"iopub.status.busy":"2022-01-12T08:51:39.603844Z","iopub.execute_input":"2022-01-12T08:51:39.604354Z","iopub.status.idle":"2022-01-12T08:51:47.848148Z","shell.execute_reply.started":"2022-01-12T08:51:39.604307Z","shell.execute_reply":"2022-01-12T08:51:47.846344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def summarizeText(text, model=model):\n    text_encoding = tokenizer(\n        text,\n        max_length=TEXT_MAX_LEN,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        add_special_tokens=True,\n        return_tensors='pt'\n    )\n        \n    generated_ids = model.generate(\n        input_ids=text_encoding['input_ids'].to(device),\n        attention_mask=text_encoding['attention_mask'].to(device),\n        max_length=SUMMARY_MAX_LEN,\n        num_beams=1,\n        repetition_penalty=2.5,\n        length_penalty=1.0,\n        early_stopping=True\n    )    \n\n    preds = [\n            tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n            for gen_id in generated_ids\n    ]\n    return \"\".join(preds)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T07:46:46.22266Z","iopub.execute_input":"2022-01-13T07:46:46.223041Z","iopub.status.idle":"2022-01-13T07:46:46.230971Z","shell.execute_reply.started":"2022-01-13T07:46:46.223001Z","shell.execute_reply":"2022-01-13T07:46:46.230283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = \"\"\"\nتضرر عشرات الآلاف من الركاب جراء إلغاء آلاف الرحلات الجوية، حيث تسبب الارتفاع الكبير في عدد حالات كوفيد 19 في نقص الموظفين.\n\nوتم إلغاء أكثر من سبعة آلاف رحلة طيران منذ يوم الجمعة وعطلة نهاية الأسبوع في عطلة عيد الميلاد، وفقًا لموقع فلايت أوير الخاص بتتبع الطائرات.\n\nويعتقد أن شركات الطيران الصينية والأمريكية هي الأكثر تضررا، مع إعلان المزيد من التأخير والإلغاء ليوم الاثنين.\n\nوتقول الشركات إن الإلغاء يرجع إلى إصابة الكثير من أعضاء أطقم الطائرات بكوفيد 19\n\nكما يضطر الموظفون الذين لم تظهر إصابتهم ولكنهم على اتصال بالمصابين إلى عزل أنفسهم.\n\"\"\"\n\nground_truth = \"إلغاء رحلات عشرات الآلاف من المسافرين بسبب الوباء\"\n\nsummary = summarizeText(text, model)\n\nprint(summary)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T07:47:11.651238Z","iopub.execute_input":"2022-01-13T07:47:11.651533Z","iopub.status.idle":"2022-01-13T07:47:11.732162Z","shell.execute_reply.started":"2022-01-13T07:47:11.651486Z","shell.execute_reply":"2022-01-13T07:47:11.731474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}